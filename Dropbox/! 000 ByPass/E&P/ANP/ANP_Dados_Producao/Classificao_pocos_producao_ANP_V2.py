import tkinter as tk
from tkinter import ttk, filedialog, scrolledtext, messagebox
import pandas as pd
import os
from pathlib import Path  # Melhor para manipular caminhos de arquivo
from collections import defaultdict
import threading

class OilWellOrganizer:
    # ... (O m√©todo __init__ e setup_ui permanecem os mesmos) ...

    # --- NOVO M√âTODO AUXILIAR ---
    def _clean_filename(self, name):
        """Limpa o nome de um campo/po√ßo para us√°-lo como nome de pasta/arquivo."""
        if pd.isna(name):
            return "SEM_NOME"
        name = str(name).strip()
        # Remove caracteres que podem ser problem√°ticos em nomes de arquivos (Windows/Linux)
        name = name.replace(':', '_').replace('/', '_').replace('\\', '_').replace('*', '_').replace('?', '_').replace('"', '_').replace('<', '_').replace('>', '_').replace('|', '_').replace(' ', '_')
        return name[:50] # Limita o comprimento por seguran√ßa
    
    # --- M√âTODO REVISADO ---
    def load_and_analyze_files(self):
        self.log_message("Carregando e analisando arquivos...", clear=True)
        self.data_frames = []
        
        # Colunas chave que queremos mapear/manter
        KEY_COLUMNS = {
            'nome po√ßo': 'Nome_Poco',
            'campo': 'Campo',
            'per√≠odo': 'Periodo_Str',
            '√≥leo (bbl/dia)': 'Oleo_bbl_dia',
            'g√°s natural (mm¬≥/dia)': 'Gas_Mm3_dia',
            '√°gua (bbl/dia)': 'Agua_bbl_dia'
        }

        try:
            for i, file in enumerate(self.csv_files, 1):
                self.log_message(f"Lendo arquivo {i}/{len(self.csv_files)}: {os.path.basename(file)}")
                
                # 1. Leitura robusta (V√≠rgula como decimal e Ponto e V√≠rgula como separador)
                # dtype='str' evita que o Pandas tente adivinhar tipos antes do tratamento
                df = pd.read_csv(file, sep=';', skiprows=4, decimal=',', encoding='latin-1', dtype=str)
                
                # 2. Padronizar Colunas
                # Remove espa√ßos, transforma para min√∫sculo para a checagem
                df.columns = df.columns.str.strip().str.lower()
                
                # Mapear e Renomear colunas
                rename_map = {}
                for col_csv, col_padrao in KEY_COLUMNS.items():
                    # Trata o caso em que o nome do CSV tem algum caracter extra
                    matched_col = next((col for col in df.columns if col_csv in col), None)
                    if matched_col:
                        rename_map[matched_col] = col_padrao

                df = df.rename(columns=rename_map)
                
                # 3. Convers√£o de Tipos e Tratamento de Data
                if 'Periodo_Str' in df.columns:
                    # Converte a coluna de per√≠odo para datetime (crucial para ordena√ß√£o correta)
                    df['Per√≠odo'] = pd.to_datetime(df['Periodo_Str'], format='%Y/%m', errors='coerce')
                    # df = df.drop(columns=['Periodo_Str']) # Opcional: remover a coluna de string
                
                # For√ßar convers√£o dos dados de produ√ß√£o para num√©rico (float)
                for col in ['Oleo_bbl_dia', 'Gas_Mm3_dia', 'Agua_bbl_dia']:
                    if col in df.columns:
                        # O 'decimal=',' j√° converteu a v√≠rgula para ponto. Agora transformamos em float
                        df[col] = pd.to_numeric(df[col], errors='coerce') 

                # Selecionar apenas as colunas de interesse (reduz a mem√≥ria e unifica a estrutura)
                cols_to_keep = list(KEY_COLUMNS.values()) + ['Per√≠odo']
                df_filtered = df.reindex(columns=cols_to_keep)
                
                self.data_frames.append(df_filtered)
                self.log_message(f"‚úì Arquivo {i} carregado e padronizado: {len(df_filtered)} registros")
            
            # An√°lise dos dados
            self.analyze_data()
            
        except Exception as e:
            self.log_message(f"‚ùå Erro ao carregar arquivos: {str(e)}")
            messagebox.showerror("Erro", f"Erro ao carregar arquivos:\n{str(e)}")

    # --- M√âTODO REVISADO ---
    def analyze_data(self):
        if not self.data_frames:
            return
        
        all_data = pd.concat(self.data_frames, ignore_index=True)
        
        # An√°lise usando os nomes de coluna padronizados
        total_registros = len(all_data)
        pocos_unicos = all_data['Nome_Poco'].nunique() if 'Nome_Poco' in all_data.columns else 0
        campos_unicos = all_data['Campo'].nunique() if 'Campo' in all_data.columns else 0
        
        if 'Campo' in all_data.columns:
            campos = sorted(all_data['Campo'].dropna().unique())
            campos_str = ", ".join(campos[:10])
            if len(campos) > 10:
                campos_str += f" ... (+{len(campos)-10} campos)"
        else:
            campos_str = "N/A"
        
        if 'Per√≠odo' in all_data.columns and not all_data['Per√≠odo'].isnull().all():
            periodo_min = all_data['Per√≠odo'].min().strftime('%Y/%m')
            periodo_max = all_data['Per√≠odo'].max().strftime('%Y/%m')
            periodo_str = f"{periodo_min} a {periodo_max}"
        else:
            periodo_str = "N/A (Erro no Per√≠odo)"
        
        summary = f"""
üìä RESUMO DOS DADOS CARREGADOS:

‚Ä¢ Total de registros: {total_registros:,}
‚Ä¢ Total de po√ßos √∫nicos: {pocos_unicos}
‚Ä¢ Total de campos √∫nicos: {campos_unicos}
‚Ä¢ Per√≠odo: {periodo_str}

üìç Campos encontrados:
{campos_str}

‚úÖ Dados prontos para processamento!
        """
        
        self.update_summary(summary)
        self.check_ready_to_process()
        self.log_message("‚úì An√°lise conclu√≠da!")


    # --- M√âTODO REVISADO ---
    # --- M√âTODO CORRIGIDO ---
    def process_files(self):
        try:
            self.log_message("="*50, clear=True)
            self.log_message("üöÄ INICIANDO PROCESSAMENTO...")
            self.log_message("="*50)
            
            self.log_message("Combinando todos os arquivos...")
            all_data = pd.concat(self.data_frames, ignore_index=True)
            
            self.log_message("Agrupando dados por Campo...")
            
            # Garante que a coluna Campo exista e trata valores vazios
            if 'Campo' not in all_data.columns:
                 raise KeyError("Coluna 'Campo' n√£o encontrada ap√≥s unifica√ß√£o dos dados.")
                 
            # 4. Agrupamento estrat√©gico: agrupa primeiro por campo
            grouped_by_field = all_data.groupby('Campo', dropna=False) # dropna=False garante que campos 'NaN' sejam processados
            
            total_campos = len(grouped_by_field)
            self.log_message(f"Total de campos a processar: {total_campos}")
            
            processed_count = 0
            
            # 5. Processar cada Campo
            for idx_c, (campo_nome, campo_data) in enumerate(grouped_by_field, 1):
                # Usa a nova fun√ß√£o auxiliar e Pathlib para seguran√ßa do caminho
                campo_dir_name = self._clean_filename(campo_nome)
                campo_dir_path = Path(self.output_dir) / campo_dir_name
                campo_dir_path.mkdir(parents=True, exist_ok=True) # Cria a pasta
                
                # Agrupar por PO√áO dentro do campo
                grouped_by_well = campo_data.groupby('Nome_Poco')
                
                # Processar cada po√ßo dentro do campo
                for poco_nome, poco_data in grouped_by_well:
                    
                    poco_nome_clean = self._clean_filename(poco_nome)
                    
                    # Ordenar por Per√≠odo (que agora √© Datetime)
                    if 'Per√≠odo' in poco_data.columns:
                        poco_data = poco_data.sort_values('Per√≠odo')
                        
                        # <<< CORRE√á√ÉO DA LINHA 206: REMOVENDO A COLUNA DATETIME >>>
                        # Remove a coluna Datetime ap√≥s us√°-la para ordena√ß√£o.
                        # Isso garante que a coluna Periodo_Str (a string original) seja usada no CSV,
                        # evitando o erro de formata√ß√£o na escrita.
                        poco_data = poco_data.drop(columns=['Per√≠odo']) 
                        
                    # Salvar arquivo do po√ßo
                    output_file = campo_dir_path / f"{poco_nome_clean}.csv"
                    # Salva usando os mesmos delimitadores de entrada
                    poco_data.to_csv(output_file, index=False, sep=';', decimal=',', encoding='latin-1')
                    
                    processed_count += 1
                
                # Log de progresso
                if idx_c % 1 == 0 or idx_c == total_campos:
                    self.log_message(f"Processando Campos: {idx_c}/{total_campos}. Po√ßos salvos at√© agora: {processed_count}")

            self.log_message("="*50)
            self.log_message("‚úÖ PROCESSAMENTO CONCLU√çDO COM SUCESSO!")
            self.log_message("="*50)
            self.log_message(f"Total de po√ßos processados: {processed_count}")
            self.log_message(f"Arquivos salvos em: {self.output_dir}")
            
            self.root.after(0, lambda: messagebox.showinfo(
                "Sucesso!", 
                f"Processamento conclu√≠do!\n\n"
                f"Total de po√ßos: {processed_count}\n"
                f"Arquivos salvos em:\n{self.output_dir}"
            ))

        except Exception as e:
            self.log_message(f"‚ùå ERRO: {str(e)}")
            self.root.after(0, lambda: messagebox.showerror("Erro", f"Erro durante processamento:\n{str(e)}"))
        
        finally:
            self.root.after(0, self.finish_processing)